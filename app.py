"""
Flask ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜
ì‹¤ì‹œê°„ í˜•íƒœ íƒì§€ ë° AR ì˜¤ë²„ë ˆì´ ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜
"""
import os
import cv2
import base64
import numpy as np
from flask import Flask, render_template, request, jsonify
from flask_socketio import SocketIO, emit
from shape_detector import ShapeDetector
from video_overlay import VideoOverlay
from hand_detector import HandDetector

# Flask ì•± ì´ˆê¸°í™”
app = Flask(__name__)
app.config['SECRET_KEY'] = 'shadow-puppet-secret-key-2025'
# Python 3.13 í˜¸í™˜ì„±ì„ ìœ„í•´ threading ëª¨ë“œ ì‚¬ìš©
socketio = SocketIO(app, cors_allowed_origins="*", async_mode='threading')

# ì „ì—­ ë³€ìˆ˜
shape_detector = None
video_overlay = None
hand_detector = None
white_background_mode = False  # í°ìƒ‰ ë°°ê²½ ëª¨ë“œ (ì† ìŠ¤ì¼ˆë ˆí†¤ë§Œ í‘œì‹œ)
mirror_mode = True  # ì¢Œìš°ë°˜ì „ ëª¨ë“œ (ê±°ìš¸ì²˜ëŸ¼ ë³´ì´ê¸°)

# íŒŒì¼ ê²½ë¡œ
REFERENCE_IMAGE_PATH = 'files/rabbit reference.png'
VIDEO_PATH = 'files/rabbit bg.mov'


def initialize_detector():
    """
    í˜•íƒœ ê°ì§€ê¸°, ë¹„ë””ì˜¤ ì˜¤ë²„ë ˆì´, ì† ê°ì§€ê¸° ì´ˆê¸°í™”
    """
    global shape_detector, video_overlay, hand_detector
    
    try:
        # íŒŒì¼ ì¡´ì¬ í™•ì¸
        if not os.path.exists(REFERENCE_IMAGE_PATH):
            print(f"ê²½ê³ : ì°¸ì¡° ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {REFERENCE_IMAGE_PATH}")
            print("files/ í´ë”ì— 'rabbit reference.png' íŒŒì¼ì„ ì¶”ê°€í•´ì£¼ì„¸ìš”.")
            return False
        
        if not os.path.exists(VIDEO_PATH):
            print(f"ê²½ê³ : ë¹„ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {VIDEO_PATH}")
            print("files/ í´ë”ì— 'rabbit bg.mov' íŒŒì¼ì„ ì¶”ê°€í•´ì£¼ì„¸ìš”.")
            return False
        
        # í˜•íƒœ ê°ì§€ê¸° ì´ˆê¸°í™”
        shape_detector = ShapeDetector(REFERENCE_IMAGE_PATH)
        print("âœ“ í˜•íƒœ ê°ì§€ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
        
        # ë¹„ë””ì˜¤ ì˜¤ë²„ë ˆì´ ì´ˆê¸°í™”
        video_overlay = VideoOverlay(VIDEO_PATH)
        print("âœ“ ë¹„ë””ì˜¤ ì˜¤ë²„ë ˆì´ ì´ˆê¸°í™” ì™„ë£Œ")
        
        # ì† ê°ì§€ê¸° ì´ˆê¸°í™”
        hand_detector = HandDetector()
        print("âœ“ ì† ê°ì§€ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
        
        return True
        
    except Exception as e:
        print(f"ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
        return False


@app.route('/')
def index():
    """
    ë©”ì¸ í˜ì´ì§€
    """
    # ê°ì§€ê¸°ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìœ¼ë©´ ì‹œë„
    if shape_detector is None or video_overlay is None:
        initialize_detector()
    
    return render_template('index.html')


@app.route('/api/status')
def status():
    """
    ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒíƒœ í™•ì¸
    """
    is_ready = shape_detector is not None and video_overlay is not None
    
    return jsonify({
        'ready': is_ready,
        'reference_image': os.path.exists(REFERENCE_IMAGE_PATH),
        'video_file': os.path.exists(VIDEO_PATH)
    })


@socketio.on('connect')
def handle_connect():
    """
    í´ë¼ì´ì–¸íŠ¸ ì—°ê²°
    """
    print(f"í´ë¼ì´ì–¸íŠ¸ ì—°ê²°: {request.sid}")
    
    # ì´ˆê¸°í™” ìƒíƒœ ì „ì†¡
    is_ready = shape_detector is not None and video_overlay is not None
    emit('status', {'ready': is_ready})


@socketio.on('disconnect')
def handle_disconnect():
    """
    í´ë¼ì´ì–¸íŠ¸ ì—°ê²° í•´ì œ
    """
    print(f"í´ë¼ì´ì–¸íŠ¸ ì—°ê²° í•´ì œ: {request.sid}")


@socketio.on('video_frame')
def handle_video_frame(data):
    """
    ë¹„ë””ì˜¤ í”„ë ˆì„ ì²˜ë¦¬
    
    Args:
        data: {
            'image': base64 ì¸ì½”ë”©ëœ ì´ë¯¸ì§€ ë°ì´í„°
        }
    """
    global shape_detector, video_overlay, hand_detector
    
    # ì´ˆê¸°í™” í™•ì¸
    if shape_detector is None or video_overlay is None or hand_detector is None:
        emit('error', {'message': 'ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'})
        return
    
    try:
        # Base64 ë””ì½”ë”©
        image_data = data.get('image', '')
        if not image_data:
            return
        
        # Data URLì—ì„œ ì‹¤ì œ base64 ë°ì´í„° ì¶”ì¶œ
        if ',' in image_data:
            image_data = image_data.split(',')[1]
        
        # Base64 -> ë°”ì´íŠ¸
        image_bytes = base64.b64decode(image_data)
        
        # ë°”ì´íŠ¸ -> NumPy ë°°ì—´ -> OpenCV ì´ë¯¸ì§€
        nparr = np.frombuffer(image_bytes, np.uint8)
        frame = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        
        if frame is None:
            emit('error', {'message': 'í”„ë ˆì„ ë””ì½”ë”© ì‹¤íŒ¨'})
            return
        
        # ì¢Œìš°ë°˜ì „ (ê±°ìš¸ ëª¨ë“œ)
        if mirror_mode:
            frame = cv2.flip(frame, 1)
        
        # ì† íƒì§€
        hand_result = hand_detector.detect(frame)
        
        # ì¶©ëŒ ê°ì§€ (ë¨¼ì € í˜•íƒœë¥¼ íƒì§€í•˜ì—¬ ìœ„ì¹˜ í™•ì¸)
        temp_detection = shape_detector.detect(frame)
        hand_collision_data = None
        
        # íƒ­ ê°ì§€ í”Œë˜ê·¸
        tap_detected = False
        tap_position = None
        
        if temp_detection['found'] and temp_detection['frame_corners'] is not None:
            # í† ë¼ ì¤‘ì‹¬ ì¢Œí‘œë„ í•¨ê»˜ ì „ë‹¬
            rabbit_center = temp_detection.get('center')
            collision_result = hand_detector.check_collision(
                hand_result['hand_centers'],
                temp_detection['frame_corners'],
                rabbit_center
            )
            if collision_result['collision']:
                hand_collision_data = collision_result
            
            # ê²€ì§€ íƒ­ ê°ì§€
            index_tips = hand_result.get('index_finger_tips', [])
            if hand_detector.check_index_tap(index_tips, temp_detection['frame_corners']):
                tap_detected = True
                # í„°ì¹˜ ìœ„ì¹˜ ì €ì¥ (ì²« ë²ˆì§¸ ê²€ì§€)
                if index_tips:
                    tap_position = index_tips[0]
        
        # í˜•íƒœ íƒì§€ (ì† ì¶©ëŒ ë°ì´í„° í¬í•¨)
        detection_result = shape_detector.detect(frame, hand_collision_data)
        
        # ê²°ê³¼ í”„ë ˆì„ ìƒì„±
        if white_background_mode:
            # í°ìƒ‰ ë°°ê²½ ëª¨ë“œ: ì›¹ìº  í™”ë©´ ëŒ€ì‹  í°ìƒ‰ ë°°ê²½
            result_frame = np.full_like(frame, 255)  # í°ìƒ‰ ë°°ê²½
        else:
            # ì¼ë°˜ ëª¨ë“œ: ì›¹ìº  í”„ë ˆì„ ë³µì‚¬ + ëª…ë„/ì±„ë„ ì¡°ì •
            result_frame = frame.copy()
            result_frame = shape_detector.apply_brightness_saturation(result_frame)
        
        # ì†ê°€ë½ ê´€ì ˆ(ëœë“œë§ˆí¬) ê·¸ë¦¬ê¸°
        if hand_result['landmarks']:
            result_frame = hand_detector.draw_landmarks(result_frame, hand_result['landmarks'])
        
        # ë¹„ë””ì˜¤ ì˜¤ë²„ë ˆì´ ë¹„í™œì„±í™” - 3D ëª¨ë¸(Three.js)ë§Œ ì‚¬ìš©
        # if (detection_result['found'] and 
        #     detection_result['frame_corners'] is not None and
        #     not detection_result.get('is_pushed_off_screen', False)):
        #     result_frame = video_overlay.overlay(result_frame, detection_result['frame_corners'])
        
        # ê²°ê³¼ í”„ë ˆì„ì„ Base64ë¡œ ì¸ì½”ë”© (í’ˆì§ˆ 70ìœ¼ë¡œ ë‚®ì¶¤ - ì†ë„ í–¥ìƒ)
        _, buffer = cv2.imencode('.jpg', result_frame, [cv2.IMWRITE_JPEG_QUALITY, 70])
        result_base64 = base64.b64encode(buffer).decode('utf-8')
        
        # ê²°ê³¼ ì „ì†¡
        emit('processed_frame', {
            'image': f'data:image/jpeg;base64,{result_base64}',
            'detection': {
                'found': detection_result['found'],
                'is_locked': detection_result['is_locked'],
                'is_permanently_active': detection_result.get('is_permanently_active', False),
                'score': detection_result['score'],
                'center': detection_result['center'],
                'angle': detection_result['angle'],
                'scale': detection_result['scale'],
                'is_grabbed': detection_result.get('is_grabbed', False),
                'is_pushed_off_screen': detection_result.get('is_pushed_off_screen', False),
                'drag_offset': detection_result.get('drag_offset', (0, 0)),
                'is_flipped': video_overlay.is_flipped
            },
            'hands': {
                'found': hand_result['hands_found'],
                'count': len(hand_result['hand_centers']),
                'index_tips': hand_result.get('index_finger_tips', []),
                'tap_detected': tap_detected,
                'tap_position': tap_position,
                'palm_detected': hand_result.get('palm_detected', False),
                'palm_center': hand_result.get('palm_center', None),
                'pinch_active': hand_result.get('pinch_active', False),
                'pinch_scale': hand_result.get('pinch_scale', 1.0),
                'pinch_distance': hand_result.get('pinch_distance', 0)
            }
        })
        
    except Exception as e:
        print(f"í”„ë ˆì„ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        emit('error', {'message': f'í”„ë ˆì„ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}'})


@socketio.on('set_adjustment')
def handle_set_adjustment(data):
    """
    ëª…ë„/ì±„ë„ ì¡°ì • íŒŒë¼ë¯¸í„° ì„¤ì •
    
    Args:
        data: {
            'brightness': int (-100 ~ +100),
            'saturation': int (-100 ~ +100)
        }
    """
    global shape_detector
    
    if shape_detector is None:
        emit('error', {'message': 'í˜•íƒœ ê°ì§€ê¸°ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'})
        return
    
    try:
        # ì¡°ì • ê°’ ë¡œê¹…
        print(f"ğŸ¨ ëª…ë„/ì±„ë„ ì¡°ì •: brightness={data.get('brightness')}, "
              f"saturation={data.get('saturation')}")
        
        shape_detector.set_adjustment(
            brightness=data.get('brightness'),
            saturation=data.get('saturation')
        )
        
        emit('adjustment_updated', {'success': True})
        
    except Exception as e:
        print(f"ëª…ë„/ì±„ë„ ì¡°ì • ì˜¤ë¥˜: {e}")
        emit('error', {'message': f'ëª…ë„/ì±„ë„ ì¡°ì • ì˜¤ë¥˜: {str(e)}'})


@socketio.on('reset_detector')
def handle_reset_detector():
    """
    í˜•íƒœ ê°ì§€ê¸° ë¦¬ì…‹
    """
    global shape_detector, video_overlay
    
    if shape_detector:
        shape_detector.reset()
    
    if video_overlay:
        video_overlay.reset()
    
    emit('detector_reset', {'success': True})


@socketio.on('set_thresholds')
def handle_set_thresholds(data):
    """
    íˆìŠ¤í…Œë¦¬ì‹œìŠ¤ ì„ê³„ê°’ ì„¤ì •
    
    Args:
        data: {
            'threshold_enter': float,
            'threshold_exit': float
        }
    """
    global shape_detector
    
    if shape_detector is None:
        emit('error', {'message': 'í˜•íƒœ ê°ì§€ê¸°ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'})
        return
    
    try:
        if 'threshold_enter' in data:
            shape_detector.threshold_enter = float(data['threshold_enter'])
        
        if 'threshold_exit' in data:
            shape_detector.threshold_exit = float(data['threshold_exit'])
        
        emit('thresholds_updated', {'success': True})
        
    except Exception as e:
        print(f"ì„ê³„ê°’ ì„¤ì • ì˜¤ë¥˜: {e}")
        emit('error', {'message': f'ì„ê³„ê°’ ì„¤ì • ì˜¤ë¥˜: {str(e)}'})


@socketio.on('set_white_background')
def handle_set_white_background(data):
    """
    í°ìƒ‰ ë°°ê²½ ëª¨ë“œ ì„¤ì • (ì›¹ìº  ë°°ê²½ ìˆ¨ê¸°ê³  ì† ìŠ¤ì¼ˆë ˆí†¤ë§Œ í‘œì‹œ)
    
    Args:
        data: {
            'enabled': bool
        }
    """
    global white_background_mode
    
    try:
        white_background_mode = data.get('enabled', False)
        print(f"ğŸ¨ í°ìƒ‰ ë°°ê²½ ëª¨ë“œ: {'í™œì„±í™”' if white_background_mode else 'ë¹„í™œì„±í™”'}")
        emit('white_background_updated', {'enabled': white_background_mode})
        
    except Exception as e:
        print(f"í°ìƒ‰ ë°°ê²½ ëª¨ë“œ ì„¤ì • ì˜¤ë¥˜: {e}")
        emit('error', {'message': f'í°ìƒ‰ ë°°ê²½ ëª¨ë“œ ì„¤ì • ì˜¤ë¥˜: {str(e)}'})


@socketio.on('set_mirror_mode')
def handle_set_mirror_mode(data):
    """
    ì¢Œìš°ë°˜ì „(ê±°ìš¸) ëª¨ë“œ ì„¤ì •
    
    Args:
        data: {
            'enabled': bool
        }
    """
    global mirror_mode
    
    try:
        mirror_mode = data.get('enabled', True)
        print(f"ğŸª ê±°ìš¸ ëª¨ë“œ: {'í™œì„±í™”' if mirror_mode else 'ë¹„í™œì„±í™”'}")
        emit('mirror_mode_updated', {'enabled': mirror_mode})
        
    except Exception as e:
        print(f"ê±°ìš¸ ëª¨ë“œ ì„¤ì • ì˜¤ë¥˜: {e}")
        emit('error', {'message': f'ê±°ìš¸ ëª¨ë“œ ì„¤ì • ì˜¤ë¥˜: {str(e)}'})


if __name__ == '__main__':
    print("=" * 60)
    print("Shadow Puppet AR - ì‹¤ì‹œê°„ í˜•íƒœ íƒì§€ ë° ë¹„ë””ì˜¤ ì˜¤ë²„ë ˆì´")
    print("=" * 60)
    
    # í´ë” ìƒì„±
    os.makedirs('files', exist_ok=True)
    os.makedirs('uploads', exist_ok=True)
    os.makedirs('static/images', exist_ok=True)
    
    # ì´ˆê¸°í™”
    print("\nì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
    initialized = initialize_detector()
    
    if not initialized:
        print("\nâš  ê²½ê³ : í•„ìˆ˜ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        print("ë‹¤ìŒ íŒŒì¼ì„ files/ í´ë”ì— ì¶”ê°€í•´ì£¼ì„¸ìš”:")
        print("  - rabbit reference.png (ì°¸ì¡° ì´ë¯¸ì§€)")
        print("  - rabbit bg.mov (ì˜¤ë²„ë ˆì´ ë¹„ë””ì˜¤)")
        print("\nì• í”Œë¦¬ì¼€ì´ì…˜ì€ ì‹¤í–‰ë˜ì§€ë§Œ íŒŒì¼ì´ ì¶”ê°€ë  ë•Œê¹Œì§€ ì‘ë™í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    
    print("\nì„œë²„ ì‹œì‘...")
    print("ë¸Œë¼ìš°ì €ì—ì„œ http://localhost:5000 ì„ ì—´ì–´ì£¼ì„¸ìš”.")
    print("=" * 60)
    
    # ì„œë²„ ì‹¤í–‰
    socketio.run(app, host='0.0.0.0', port=5000, debug=True)

