"""
ë¹„ë””ì˜¤ ì˜¤ë²„ë ˆì´ ëª¨ë“ˆ
íƒì§€ëœ í˜•íƒœ ìœ„ì— ë¹„ë””ì˜¤ë¥¼ ì¦ê°•í˜„ì‹¤ ìŠ¤íƒ€ì¼ë¡œ ì˜¤ë²„ë ˆì´í•©ë‹ˆë‹¤.
"""
import cv2
import numpy as np


class VideoOverlay:
    """
    ë¹„ë””ì˜¤ ì˜¤ë²„ë ˆì´ í´ë˜ìŠ¤
    - ì›ê·¼ ë³€í™˜(Perspective Transform)ì„ ì‚¬ìš©í•œ ë¹„ë””ì˜¤ ì›Œí•‘
    - ê³±í•˜ê¸° ë¸”ë Œë“œ ëª¨ë“œë¡œ ìì—°ìŠ¤ëŸ¬ìš´ í•©ì„±
    """
    
    def __init__(self, video_path):
        """
        ì´ˆê¸°í™”
        
        Args:
            video_path: ì˜¤ë²„ë ˆì´í•  ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
        """
        self.video_path = video_path
        self.video_capture = cv2.VideoCapture(video_path)
        
        if not self.video_capture.isOpened():
            raise ValueError(f"ë¹„ë””ì˜¤ íŒŒì¼ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}")
        
        # ë¹„ë””ì˜¤ ì •ë³´
        self.video_width = int(self.video_capture.get(cv2.CAP_PROP_FRAME_WIDTH))
        self.video_height = int(self.video_capture.get(cv2.CAP_PROP_FRAME_HEIGHT))
        self.fps = self.video_capture.get(cv2.CAP_PROP_FPS)
        self.total_frames = int(self.video_capture.get(cv2.CAP_PROP_FRAME_COUNT))
        
        self.current_frame_idx = 0
        self.current_video_frame = None
        
        # ì¢Œìš° ë°˜ì „ ìƒíƒœ
        self.is_flipped = False
        
        # ì²« í”„ë ˆì„ ë¡œë“œ
        self._read_next_frame()
    
    def toggle_flip(self):
        """
        ì¢Œìš° ë°˜ì „ í† ê¸€
        """
        self.is_flipped = not self.is_flipped
        flip_status = "ë°˜ì „ë¨" if self.is_flipped else "ì›ë³¸"
        print(f"ğŸ”„ ë¹„ë””ì˜¤ ì¢Œìš° ë°˜ì „: {flip_status}")
    
    def _read_next_frame(self):
        """
        ë‹¤ìŒ ë¹„ë””ì˜¤ í”„ë ˆì„ ì½ê¸°
        """
        ret, frame = self.video_capture.read()
        
        if not ret:
            # ë¹„ë””ì˜¤ ëì— ë„ë‹¬í•˜ë©´ ì²˜ìŒìœ¼ë¡œ ëŒì•„ê°€ê¸°
            self.video_capture.set(cv2.CAP_PROP_POS_FRAMES, 0)
            ret, frame = self.video_capture.read()
            self.current_frame_idx = 0
        
        if ret:
            self.current_video_frame = frame
            self.current_frame_idx += 1
        
        return ret
    
    def overlay(self, base_frame, frame_corners):
        """
        ë¹„ë””ì˜¤ë¥¼ ë² ì´ìŠ¤ í”„ë ˆì„ì— ì˜¤ë²„ë ˆì´
        
        Args:
            base_frame: ë² ì´ìŠ¤ í”„ë ˆì„ (BGR)
            frame_corners: í”„ë ˆì„ 4ê°œ ì½”ë„ˆ ì¢Œí‘œ [[x1,y1], [x2,y2], [x3,y3], [x4,y4]]
                          (ì¢Œìƒë‹¨, ìš°ìƒë‹¨, ìš°í•˜ë‹¨, ì¢Œí•˜ë‹¨ ìˆœì„œ)
        
        Returns:
            ì˜¤ë²„ë ˆì´ëœ í”„ë ˆì„
        """
        if self.current_video_frame is None:
            return base_frame
        
        # ë‹¤ìŒ í”„ë ˆì„ ì½ê¸°
        self._read_next_frame()
        
        # í˜„ì¬ ë¹„ë””ì˜¤ í”„ë ˆì„ (ì¢Œìš° ë°˜ì „ ì ìš©)
        video_frame = self.current_video_frame.copy()
        if self.is_flipped:
            video_frame = cv2.flip(video_frame, 1)  # 1 = ì¢Œìš° ë°˜ì „
        
        # ì†ŒìŠ¤ ì¢Œí‘œ (ë¹„ë””ì˜¤ì˜ 4ê°œ ì½”ë„ˆ)
        src_pts = np.float32([
            [0, 0],
            [self.video_width - 1, 0],
            [self.video_width - 1, self.video_height - 1],
            [0, self.video_height - 1]
        ])
        
        # ëª©ì ì§€ ì¢Œí‘œ (íƒì§€ëœ í˜•íƒœì˜ í”„ë ˆì„ ì½”ë„ˆ)
        dst_pts = np.float32(frame_corners)
        
        # ì›ê·¼ ë³€í™˜ í–‰ë ¬ ê³„ì‚°
        try:
            transform_matrix = cv2.getPerspectiveTransform(src_pts, dst_pts)
        except cv2.error:
            # ë³€í™˜ ì‹¤íŒ¨ ì‹œ ì›ë³¸ ë°˜í™˜
            return base_frame
        
        # ë¹„ë””ì˜¤ í”„ë ˆì„ ì›Œí•‘
        frame_h, frame_w = base_frame.shape[:2]
        warped_video = cv2.warpPerspective(
            video_frame,
            transform_matrix,
            (frame_w, frame_h),
            flags=cv2.INTER_LINEAR,
            borderMode=cv2.BORDER_CONSTANT,
            borderValue=(255, 255, 255)  # í°ìƒ‰ ë°°ê²½
        )
        
        # ë§ˆìŠ¤í¬ ìƒì„± (ì›Œí•‘ëœ ì˜ì—­)
        mask = cv2.warpPerspective(
            np.ones((self.video_height, self.video_width), dtype=np.uint8) * 255,
            transform_matrix,
            (frame_w, frame_h),
            flags=cv2.INTER_LINEAR,
            borderMode=cv2.BORDER_CONSTANT,
            borderValue=(0,)
        )
        
        # ë§ˆìŠ¤í¬ë¥¼ 3ì±„ë„ë¡œ í™•ì¥
        mask_3ch = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)
        
        # ê³±í•˜ê¸° ë¸”ë Œë“œ ëª¨ë“œ ì ìš©
        # result = (base_frame * warped_video) / 255
        base_float = base_frame.astype(np.float32)
        warped_float = warped_video.astype(np.float32)
        mask_float = mask_3ch.astype(np.float32) / 255.0
        
        # ë¸”ë Œë”©
        blended = (base_float * warped_float) / 255.0
        
        # ë§ˆìŠ¤í¬ ì ìš©í•˜ì—¬ ì˜¤ë²„ë ˆì´ ì˜ì—­ë§Œ í•©ì„±
        result = base_float.copy()
        result = result * (1 - mask_float) + blended * mask_float
        
        result = np.clip(result, 0, 255).astype(np.uint8)
        
        return result
    
    def set_frame(self, frame_idx):
        """
        íŠ¹ì • í”„ë ˆì„ìœ¼ë¡œ ì´ë™
        
        Args:
            frame_idx: í”„ë ˆì„ ì¸ë±ìŠ¤
        """
        frame_idx = max(0, min(frame_idx, self.total_frames - 1))
        self.video_capture.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
        self.current_frame_idx = frame_idx
        self._read_next_frame()
    
    def reset(self):
        """
        ë¹„ë””ì˜¤ë¥¼ ì²˜ìŒìœ¼ë¡œ ë¦¬ì…‹
        """
        self.set_frame(0)
    
    def release(self):
        """
        ë¹„ë””ì˜¤ ìº¡ì²˜ í•´ì œ
        """
        if self.video_capture is not None:
            self.video_capture.release()
            self.video_capture = None
    
    def __del__(self):
        """
        ì†Œë©¸ì
        """
        self.release()

