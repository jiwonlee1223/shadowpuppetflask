"""
í˜•íƒœ ê°ì§€ ëª¨ë“ˆ
OpenCVì˜ Hu Moments ê¸°ë°˜ í˜•íƒœ ë§¤ì¹­ì„ ì‚¬ìš©í•˜ì—¬ ì‹¤ì‹œê°„ìœ¼ë¡œ íŠ¹ì • í˜•íƒœë¥¼ íƒì§€í•©ë‹ˆë‹¤.
"""
import cv2
import numpy as np
import time


class ShapeDetector:
    """
    ì‹¤ì‹œê°„ í˜•íƒœ íƒì§€ í´ë˜ìŠ¤
    - Hu Moments ê¸°ë°˜ í˜•íƒœ ë§¤ì¹­
    - íˆìŠ¤í…Œë¦¬ì‹œìŠ¤ ê¸°ë°˜ ì ê¸ˆ ë©”ì»¤ë‹ˆì¦˜
    - ì§€ìˆ˜ ì´ë™ í‰ê· (EMA)ì„ ì‚¬ìš©í•œ ë¶€ë“œëŸ¬ìš´ ì¶”ì 
    - ëª…ë„/ì±„ë„ ì¡°ì •
    """
    
    def __init__(self, reference_image_path):
        """
        ì´ˆê¸°í™”
        
        Args:
            reference_image_path: ì°¸ì¡° ì´ë¯¸ì§€ ê²½ë¡œ (íƒì§€í•  í˜•íƒœ)
        """
        # ì°¸ì¡° ì´ë¯¸ì§€ ë¡œë“œ
        self.reference_image = cv2.imread(reference_image_path)
        if self.reference_image is None:
            raise ValueError(f"ì°¸ì¡° ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {reference_image_path}")
        
        # ì°¸ì¡° ìœ¤ê³½ì„  ì¶”ì¶œ
        self.reference_contour = self._extract_reference_contour()
        if self.reference_contour is None:
            raise ValueError("ì°¸ì¡° ì´ë¯¸ì§€ì—ì„œ ìœ íš¨í•œ ìœ¤ê³½ì„ ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        # ëª…ë„/ì±„ë„ ì¡°ì • íŒŒë¼ë¯¸í„°
        self.brightness = 0  # -100 ~ +100
        self.saturation = 0  # -100 ~ +100
        
        # íˆìŠ¤í…Œë¦¬ì‹œìŠ¤ íŒŒë¼ë¯¸í„°
        self.threshold_enter = 0.25  # ì ê¸ˆ ì§„ì… ì„ê³„ê°’ (ë‚®ì„ìˆ˜ë¡ ì—„ê²©)
        self.threshold_exit = 0.50   # ì ê¸ˆ í•´ì œ ì„ê³„ê°’ (ë” ê´€ëŒ€í•¨)
        self.lock_count_enter = 12   # ì ê¸ˆ ì§„ì… í•„ìš” í”„ë ˆì„ ìˆ˜
        self.lock_count_exit = 8     # ì ê¸ˆ í•´ì œ í•„ìš” í”„ë ˆì„ ìˆ˜
        
        # ì ê¸ˆ ìƒíƒœ
        self.is_locked = False
        self.good_frames = 0
        self.bad_frames = 0
        
        # ì˜êµ¬ í™œì„±í™” (3ì´ˆ ì´ìƒ íƒì§€ ì‹œ)
        self.permanent_activation_time = 3.0  # 3ì´ˆ
        self.locked_start_time = None
        self.is_permanently_active = False
        self.last_valid_result = None  # ë§ˆì§€ë§‰ ìœ íš¨í•œ íƒì§€ ê²°ê³¼ ì €ì¥
        
        # ì• ë‹ˆë©”ì´ì…˜ ì¡ê¸° ë° ë“œë˜ê·¸ (ì† ì¸í„°ë™ì…˜)
        self.drag_offset_x = 0.0  # Xì¶• ë“œë˜ê·¸ ì˜¤í”„ì…‹
        self.drag_offset_y = 0.0  # Yì¶• ë“œë˜ê·¸ ì˜¤í”„ì…‹
        self.is_grabbed = False  # ì¡í˜”ëŠ”ì§€ ì—¬ë¶€
        self.grab_hand_position = None  # ì¡ì€ ì†ì˜ ìœ„ì¹˜
        self.last_hand_position = None  # ë§ˆì§€ë§‰ ì† ìœ„ì¹˜ (ë¶€ë“œëŸ¬ìš´ ì´ë™)
        self.drag_smoothing = 0.3  # ë“œë˜ê·¸ ìŠ¤ë¬´ë”© ê³„ìˆ˜ (0~1, ë‚®ì„ìˆ˜ë¡ ë¶€ë“œëŸ¬ì›€)
        self.is_pushed_off_screen = False  # í™”ë©´ ë°–ìœ¼ë¡œ ë‚˜ê°”ëŠ”ì§€ ì—¬ë¶€
        self.screen_width = 640  # í™”ë©´ ë„ˆë¹„ (ì´ˆê¸°ê°’)
        self.screen_height = 480  # í™”ë©´ ë†’ì´ (ì´ˆê¸°ê°’)
        
        # ë¶€ë“œëŸ¬ìš´ ì¶”ì ì„ ìœ„í•œ EMA
        self.smoothed_cx = None
        self.smoothed_cy = None
        self.smoothed_angle = None
        self.smoothed_scale = None
        self.smoothed_frame_cx = None
        self.smoothed_frame_cy = None
        
        self.alpha = 0.3          # ì¼ë°˜ EMA ê³„ìˆ˜
        self.alpha_frame = 0.5    # í”„ë ˆì„ ì¤‘ì‹¬ EMA ê³„ìˆ˜ (ë” ë¶€ë“œëŸ½ê²Œ)
    
    def _extract_reference_contour(self):
        """
        ì°¸ì¡° ì´ë¯¸ì§€ì—ì„œ ê°€ì¥ í° ìœ¤ê³½ì„  ì¶”ì¶œ
        
        Returns:
            ì°¸ì¡° ìœ¤ê³½ì„  (numpy array)
        """
        gray = cv2.cvtColor(self.reference_image, cv2.COLOR_BGR2GRAY)
        
        # ì ì‘í˜• ì„ê³„ê°’
        binary = cv2.adaptiveThreshold(
            gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
            cv2.THRESH_BINARY_INV, 11, 2
        )
        
        # ëª¨í´ë¡œì§€ ì—°ì‚°ìœ¼ë¡œ ë…¸ì´ì¦ˆ ì œê±°
        kernel = np.ones((3, 3), np.uint8)
        binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel, iterations=2)
        binary = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel, iterations=1)
        
        # ìœ¤ê³½ì„  ì°¾ê¸°
        contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        if not contours:
            return None
        
        # ê°€ì¥ í° ìœ¤ê³½ì„  ë°˜í™˜
        return max(contours, key=cv2.contourArea)
    
    def apply_brightness_saturation(self, image):
        """
        ëª…ë„/ì±„ë„ ì¡°ì • ì ìš©
        
        Args:
            image: ì…ë ¥ ì´ë¯¸ì§€ (BGR ì»¬ëŸ¬ ë˜ëŠ” ê·¸ë ˆì´ìŠ¤ì¼€ì¼)
        
        Returns:
            ì¡°ì •ëœ ì´ë¯¸ì§€
        """
        # ì¡°ì • ê°’ì´ ê¸°ë³¸ê°’ì´ë©´ ì›ë³¸ ë°˜í™˜
        if self.brightness == 0 and self.saturation == 0:
            return image
        
        # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ì´ë©´ ëª…ë„ë§Œ ì¡°ì •
        if len(image.shape) == 2:
            # ëª…ë„ ì¡°ì • (ë‹¨ìˆœ ë§ì…ˆ)
            if self.brightness != 0:
                img = image.astype(np.float32)
                img = img + self.brightness
                img = np.clip(img, 0, 255)
                return img.astype(np.uint8)
            return image
        
        # ì»¬ëŸ¬ ì´ë¯¸ì§€: HSVë¡œ ë³€í™˜í•˜ì—¬ ì¡°ì •
        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV).astype(np.float32)
        
        # ì±„ë„ ì¡°ì • (S ì±„ë„)
        if self.saturation != 0:
            # -100 ~ +100ì„ 0.0 ~ 2.0 ë°°ìœ¨ë¡œ ë³€í™˜
            sat_scale = 1.0 + (self.saturation / 100.0)
            hsv[:, :, 1] = hsv[:, :, 1] * sat_scale
            hsv[:, :, 1] = np.clip(hsv[:, :, 1], 0, 255)
        
        # ëª…ë„ ì¡°ì • (V ì±„ë„)
        if self.brightness != 0:
            hsv[:, :, 2] = hsv[:, :, 2] + self.brightness
            hsv[:, :, 2] = np.clip(hsv[:, :, 2], 0, 255)
        
        # BGRë¡œ ë‹¤ì‹œ ë³€í™˜
        hsv = hsv.astype(np.uint8)
        result = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
        
        return result
    
    def set_adjustment(self, brightness=None, saturation=None):
        """
        ëª…ë„/ì±„ë„ ì¡°ì • íŒŒë¼ë¯¸í„° ì„¤ì •
        
        Args:
            brightness: ëª…ë„ (-100 ~ +100)
            saturation: ì±„ë„ (-100 ~ +100)
        """
        if brightness is not None:
            self.brightness = max(-100, min(100, int(brightness)))
        if saturation is not None:
            self.saturation = max(-100, min(100, int(saturation)))
    
    def apply_grab(self, hand_position, rabbit_center):
        """
        ì†ìœ¼ë¡œ í† ë¼ ì¡ê¸°
        
        Args:
            hand_position: ì†ì˜ í˜„ì¬ ìœ„ì¹˜ (x, y)
            rabbit_center: í† ë¼ì˜ ì¤‘ì‹¬ ìœ„ì¹˜ (x, y)
        """
        if not self.is_grabbed:
            # ì²˜ìŒ ì¡ì„ ë•Œ
            self.is_grabbed = True
            self.grab_hand_position = hand_position
            self.last_hand_position = hand_position
            print("ğŸ° í† ë¼ë¥¼ ì¡ì•˜ìŠµë‹ˆë‹¤!")
        else:
            # ì´ë¯¸ ì¡ê³  ìˆì„ ë•Œ - ì†ì˜ ì´ë™ëŸ‰ë§Œí¼ í† ë¼ ì´ë™
            if self.last_hand_position:
                # ì†ì˜ ì´ë™ëŸ‰ ê³„ì‚°
                delta_x = hand_position[0] - self.last_hand_position[0]
                delta_y = hand_position[1] - self.last_hand_position[1]
                
                # ë¶€ë“œëŸ¬ìš´ ì´ë™ (ìŠ¤ë¬´ë”© ì ìš©)
                self.drag_offset_x += delta_x * self.drag_smoothing
                self.drag_offset_y += delta_y * self.drag_smoothing
            
            # í˜„ì¬ ì† ìœ„ì¹˜ ì €ì¥
            self.last_hand_position = hand_position
            self.grab_hand_position = hand_position
    
    def release_grab(self):
        """
        í† ë¼ ë†“ê¸°
        """
        if self.is_grabbed:
            self.is_grabbed = False
            self.grab_hand_position = None
            self.last_hand_position = None
            print("ğŸ° í† ë¼ë¥¼ ë†“ì•˜ìŠµë‹ˆë‹¤!")
    
    def update_drag_physics(self):
        """
        ë“œë˜ê·¸ ë¬¼ë¦¬ ì—…ë°ì´íŠ¸ (ë§¤ í”„ë ˆì„ë§ˆë‹¤ í˜¸ì¶œ)
        """
        # í™”ë©´ ë°–ìœ¼ë¡œ ë‚˜ê°”ëŠ”ì§€ í™•ì¸
        if (abs(self.drag_offset_x) > self.screen_width or 
            abs(self.drag_offset_y) > self.screen_height):
            self.is_pushed_off_screen = True
    
    def detect(self, frame, hand_collision_data=None):
        """
        í”„ë ˆì„ì—ì„œ í˜•íƒœ íƒì§€
        
        Args:
            frame: ì…ë ¥ í”„ë ˆì„ (BGR)
            hand_collision_data: ì† ì¶©ëŒ ë°ì´í„° (ì„ íƒì )
                {
                    'collision': bool,
                    'collision_point': tuple (x, y),
                    'rabbit_center': tuple (x, y)  # ì¶”ê°€
                }
        
        Returns:
            dict: {
                'found': bool - í˜•íƒœë¥¼ ì°¾ì•˜ëŠ”ì§€ ì—¬ë¶€
                'contour': numpy array - íƒì§€ëœ ìœ¤ê³½ì„ 
                'center': tuple - ì¤‘ì‹¬ì  (cx, cy)
                'angle': float - íšŒì „ ê°ë„
                'scale': float - ìŠ¤ì¼€ì¼
                'score': float - ë§¤ì¹­ ì ìˆ˜
                'frame_corners': list - í”„ë ˆì„ 4ê°œ ì½”ë„ˆ ì¢Œí‘œ
                'is_locked': bool - ì ê¸ˆ ìƒíƒœ
                'drag_offset': tuple - ë“œë˜ê·¸ ì˜¤í”„ì…‹ (x, y)
                'is_grabbed': bool - ì¡íŒ ìƒíƒœ
                'is_pushed_off_screen': bool - í™”ë©´ ë°– ì—¬ë¶€
            }
        """
        # í™”ë©´ í¬ê¸° ì—…ë°ì´íŠ¸
        self.screen_height, self.screen_width = frame.shape[:2]
        
        # ì† ì¡ê¸°/ë“œë˜ê·¸ ì²˜ë¦¬
        if hand_collision_data and hand_collision_data.get('collision'):
            # ì†ì´ í† ë¼ì— ë‹¿ì•„ìˆìŒ - ì¡ê¸°
            hand_pos = hand_collision_data.get('collision_point')
            rabbit_center = hand_collision_data.get('rabbit_center')
            if hand_pos and rabbit_center:
                self.apply_grab(hand_pos, rabbit_center)
        else:
            # ì†ì´ í† ë¼ì—ì„œ ë©€ì–´ì§ - ë†“ê¸°
            if self.is_grabbed:
                self.release_grab()
        
        # ë“œë˜ê·¸ ë¬¼ë¦¬ ì—…ë°ì´íŠ¸
        self.update_drag_physics()
        # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        
        # ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ë¡œ ë…¸ì´ì¦ˆ ì œê±° (ì»¤ë„ í¬ê¸° ì¶•ì†Œ - ì†ë„ í–¥ìƒ)
        gray = cv2.GaussianBlur(gray, (3, 3), 0)
        
        # ì ì‘í˜• ì„ê³„ê°’
        binary = cv2.adaptiveThreshold(
            gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
            cv2.THRESH_BINARY_INV, 11, 2
        )
        
        # ëª¨í´ë¡œì§€ ì—°ì‚° (ë°˜ë³µ íšŸìˆ˜ ì¤„ì„ - ì†ë„ í–¥ìƒ)
        kernel = np.ones((3, 3), np.uint8)
        binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel, iterations=1)
        # MORPH_OPEN ìƒëµ (ì†ë„ í–¥ìƒ)
        
        # ìœ¤ê³½ì„  ì°¾ê¸°
        contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        if not contours:
            return self._no_detection_result()
        
        # í•„í„°ë§ ë° ë§¤ì¹­
        best_match = None
        best_score = float('inf')
        
        frame_h, frame_w = frame.shape[:2]
        max_area = frame_h * frame_w * 0.5  # í”„ë ˆì„ì˜ 50%
        
        for contour in contours:
            area = cv2.contourArea(contour)
            
            # ë©´ì  í•„í„°
            if area < 2000 or area > max_area:
                continue
            
            # ì¢…íš¡ë¹„ í•„í„°
            x, y, w, h = cv2.boundingRect(contour)
            aspect_ratio = w / float(h) if h > 0 else 0
            if aspect_ratio < 0.5 or aspect_ratio > 2.0:
                continue
            
            # í˜•íƒœ ë§¤ì¹­
            score = cv2.matchShapes(self.reference_contour, contour, cv2.CONTOURS_MATCH_I3, 0)
            
            if score < best_score:
                best_score = score
                best_match = contour
        
        # íˆìŠ¤í…Œë¦¬ì‹œìŠ¤ ì ìš©
        if best_match is not None:
            if not self.is_locked:
                # ì ê¸ˆ í•´ì œ ìƒíƒœ
                if best_score < self.threshold_enter:
                    self.good_frames += 1
                    if self.good_frames >= self.lock_count_enter:
                        self.is_locked = True
                        self.bad_frames = 0
                        # ì ê¸ˆ ì‹œì‘ ì‹œê°„ ê¸°ë¡
                        self.locked_start_time = time.time()
                else:
                    self.good_frames = 0
            else:
                # ì ê¸ˆ ìƒíƒœ
                if best_score > self.threshold_exit:
                    self.bad_frames += 1
                    if self.bad_frames >= self.lock_count_exit:
                        # ì˜êµ¬ í™œì„±í™” ëª¨ë“œê°€ ì•„ë‹ˆë©´ ì ê¸ˆ í•´ì œ
                        if not self.is_permanently_active:
                            self.is_locked = False
                            self.good_frames = 0
                            self.locked_start_time = None
                else:
                    self.bad_frames = 0
                
                # 3ì´ˆ ì´ìƒ ì ê¸ˆ ìƒíƒœ ìœ ì§€ ì‹œ ì˜êµ¬ í™œì„±í™”
                if self.locked_start_time is not None:
                    elapsed = time.time() - self.locked_start_time
                    if elapsed >= self.permanent_activation_time:
                        self.is_permanently_active = True
        else:
            # ë§¤ì¹­ ì‹¤íŒ¨
            if self.is_locked:
                self.bad_frames += 1
                if self.bad_frames >= self.lock_count_exit:
                    # ì˜êµ¬ í™œì„±í™” ëª¨ë“œê°€ ì•„ë‹ˆë©´ ì ê¸ˆ í•´ì œ
                    if not self.is_permanently_active:
                        self.is_locked = False
                        self.good_frames = 0
                        self.locked_start_time = None
            else:
                self.good_frames = 0
        
        # ì˜êµ¬ í™œì„±í™” ëª¨ë“œ: ë§ˆì§€ë§‰ ìœ íš¨í•œ ê²°ê³¼ ë°˜í™˜
        if self.is_permanently_active:
            if best_match is not None and self.is_locked:
                # ìƒˆë¡œìš´ íƒì§€ ê²°ê³¼ ì €ì¥
                result = self._extract_shape_info(best_match, best_score, frame.shape)
                result['is_locked'] = self.is_locked
                result['is_permanently_active'] = True
                self.last_valid_result = result
                return result
            elif self.last_valid_result is not None:
                # íƒì§€ ì‹¤íŒ¨ ì‹œ ë§ˆì§€ë§‰ ê²°ê³¼ ë°˜í™˜
                return self.last_valid_result
        
        # ì¼ë°˜ ëª¨ë“œ: ì ê¸ˆ ìƒíƒœê°€ ì•„ë‹ˆë©´ íƒì§€ ê²°ê³¼ ì—†ìŒ
        if not self.is_locked or best_match is None:
            return self._no_detection_result()
        
        # íƒì§€ ì„±ê³µ - ì •ë³´ ì¶”ì¶œ
        result = self._extract_shape_info(best_match, best_score, frame.shape)
        result['is_locked'] = self.is_locked
        result['is_permanently_active'] = False
        
        return result
    
    def _extract_shape_info(self, contour, score, frame_shape):
        """
        íƒì§€ëœ í˜•íƒœì—ì„œ ì •ë³´ ì¶”ì¶œ
        
        Args:
            contour: ìœ¤ê³½ì„ 
            score: ë§¤ì¹­ ì ìˆ˜
            frame_shape: í”„ë ˆì„ í¬ê¸°
        
        Returns:
            dict: íƒì§€ ì •ë³´
        """
        # ëª¨ë©˜íŠ¸ ê³„ì‚°
        M = cv2.moments(contour)
        if M['m00'] == 0:
            return self._no_detection_result()
        
        # ì¤‘ì‹¬ì 
        cx = M['m10'] / M['m00']
        cy = M['m01'] / M['m00']
        
        # íšŒì „ ê°ë„
        angle = 0.5 * np.arctan2(2 * M['mu11'], M['mu20'] - M['mu02'])
        angle_deg = np.degrees(angle)
        
        # ìŠ¤ì¼€ì¼ ê³„ì‚°
        ref_M = cv2.moments(self.reference_contour)
        ref_area = ref_M['m00']
        curr_area = M['m00']
        scale = np.sqrt(curr_area / ref_area) if ref_area > 0 else 1.0
        
        # ë¶€ë“œëŸ¬ìš´ ì¶”ì  (EMA)
        if self.smoothed_cx is None:
            # ì´ˆê¸°í™”
            self.smoothed_cx = cx
            self.smoothed_cy = cy
            self.smoothed_angle = angle_deg
            self.smoothed_scale = scale
        else:
            # EMA ì ìš©
            self.smoothed_cx = self.alpha * cx + (1 - self.alpha) * self.smoothed_cx
            self.smoothed_cy = self.alpha * cy + (1 - self.alpha) * self.smoothed_cy
            self.smoothed_scale = self.alpha * scale + (1 - self.alpha) * self.smoothed_scale
            
            # ê°ë„ëŠ” ìˆœí™˜ í‰ê· 
            angle_diff = angle_deg - self.smoothed_angle
            if angle_diff > 180:
                angle_diff -= 360
            elif angle_diff < -180:
                angle_diff += 360
            self.smoothed_angle += self.alpha * angle_diff
        
        # í”„ë ˆì„ ì½”ë„ˆ ê³„ì‚° (ì°¸ì¡° ì´ë¯¸ì§€ ë¹„ìœ¨ ì‚¬ìš©)
        # ìƒë‹¨:í† ë¼:í•˜ë‹¨ = 100:294:38
        # ì¢Œ:í† ë¼:ìš° = 207:364:200
        ref_h, ref_w = self.reference_image.shape[:2]
        
        # í† ë¼ì˜ ë°”ìš´ë”© ë°•ìŠ¤
        rabbit_x, rabbit_y, rabbit_w, rabbit_h = cv2.boundingRect(self.reference_contour)
        
        # í”„ë ˆì„ í¬ê¸° ê³„ì‚°
        frame_w = rabbit_w + 207 + 200  # ì¢Œ + í† ë¼ + ìš°
        frame_h = rabbit_h + 100 + 38   # ìƒ + í† ë¼ + í•˜
        
        # í”„ë ˆì„ ì¤‘ì‹¬ (ë¶€ë“œëŸ¬ìš´ ì¶”ì )
        frame_cx_raw = self.smoothed_cx
        frame_cy_raw = self.smoothed_cy
        
        if self.smoothed_frame_cx is None:
            self.smoothed_frame_cx = frame_cx_raw
            self.smoothed_frame_cy = frame_cy_raw
        else:
            self.smoothed_frame_cx = self.alpha_frame * frame_cx_raw + (1 - self.alpha_frame) * self.smoothed_frame_cx
            self.smoothed_frame_cy = self.alpha_frame * frame_cy_raw + (1 - self.alpha_frame) * self.smoothed_frame_cy
        
        # í”„ë ˆì„ 4ê°œ ì½”ë„ˆ (ìŠ¤ì¼€ì¼ ì ìš©)
        scaled_frame_w = frame_w * self.smoothed_scale
        scaled_frame_h = frame_h * self.smoothed_scale
        
        half_w = scaled_frame_w / 2
        half_h = scaled_frame_h / 2
        
        # íšŒì „ í–‰ë ¬
        angle_rad = np.radians(self.smoothed_angle)
        cos_a = np.cos(angle_rad)
        sin_a = np.sin(angle_rad)
        
        # 4ê°œ ì½”ë„ˆ (íšŒì „ ì ìš©)
        corners = []
        for dx, dy in [(-half_w, -half_h), (half_w, -half_h), 
                       (half_w, half_h), (-half_w, half_h)]:
            # íšŒì „
            rx = dx * cos_a - dy * sin_a
            ry = dx * sin_a + dy * cos_a
            # ì´ë™
            corners.append([
                self.smoothed_frame_cx + rx,
                self.smoothed_frame_cy + ry
            ])
        
        # ë“œë˜ê·¸ ì˜¤í”„ì…‹ ì ìš©
        dragged_corners = []
        for corner in corners:
            dragged_corners.append([
                corner[0] + self.drag_offset_x,
                corner[1] + self.drag_offset_y
            ])
        
        return {
            'found': True,
            'contour': contour,
            'center': (self.smoothed_cx + self.drag_offset_x, 
                      self.smoothed_cy + self.drag_offset_y),
            'angle': self.smoothed_angle,
            'scale': self.smoothed_scale,
            'score': score,
            'frame_corners': dragged_corners,
            'is_locked': True,
            'drag_offset': (self.drag_offset_x, self.drag_offset_y),
            'is_grabbed': self.is_grabbed,
            'is_pushed_off_screen': self.is_pushed_off_screen
        }
    
    def _no_detection_result(self):
        """
        íƒì§€ ì‹¤íŒ¨ ê²°ê³¼ ë°˜í™˜
        """
        return {
            'found': False,
            'contour': None,
            'center': None,
            'angle': None,
            'scale': None,
            'score': None,
            'frame_corners': None,
            'is_locked': self.is_locked,
            'is_permanently_active': self.is_permanently_active,
            'drag_offset': (self.drag_offset_x, self.drag_offset_y),
            'is_grabbed': self.is_grabbed,
            'is_pushed_off_screen': self.is_pushed_off_screen
        }
    
    def reset(self):
        """
        ì¶”ì  ìƒíƒœ ë¦¬ì…‹
        """
        self.is_locked = False
        self.good_frames = 0
        self.bad_frames = 0
        self.smoothed_cx = None
        self.smoothed_cy = None
        self.smoothed_angle = None
        self.smoothed_scale = None
        self.smoothed_frame_cx = None
        self.smoothed_frame_cy = None
        # ì˜êµ¬ í™œì„±í™” ëª¨ë“œ ë¦¬ì…‹
        self.is_permanently_active = False
        self.locked_start_time = None
        self.last_valid_result = None
        # ë“œë˜ê·¸ íš¨ê³¼ ë¦¬ì…‹
        self.drag_offset_x = 0.0
        self.drag_offset_y = 0.0
        self.is_grabbed = False
        self.grab_hand_position = None
        self.last_hand_position = None
        self.is_pushed_off_screen = False

